{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "In this notebook we will cover the basic concepts of inference on a trained U-net in Tensorflow. We will be specifically loading a network trained to perform segmentation of brain tumors from multimodal MR images. The data that we will be using in this tutorial comes from the MICCAI Brain Tumor Segmentation Challenge (BRaTS). More information about he BRaTS Challenge can be found here: http://braintumorsegmentation.org/\n",
    "\n",
    "For basics of Tensorflow operation, neural networks and training, consider reviewing the preceding lectures in this series:\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; **01 - Introduction to Data, Tensorflow and Deep Learning** <br/>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; **02 - Training a Classifier** <br/>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; **03 - Inference with a Classifier**<br/>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; **04 - Training a U-Net**\n",
    "\n",
    "**Note:** Before running this notebook, be sure turn off the kernel used for training. You can keep the corresponding tab open in your browser to retrain later, just shut down the kernel from the top menu now so that it's resources can be used here (`Kernel` > `Shutdown`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing modules\n",
    "\n",
    "To visualize inference for our simple classifer implementation, we will require two open-source libraries (`tensorflow`, `numpy`) as well as our custom modules created for this tutorial (`utils`, `data`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf, numpy as np\n",
    "import data\n",
    "from utils import imshow\n",
    "\n",
    "data.set_root(loc='/data/brats/npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading trained model\n",
    "\n",
    "Our trained model has been saved in the `../exp_unet/checkpoint` direction. Alternatively, you can also choose instead to load a pretrained model located in `../pretrained/unet`. Based on your preference, set the model dir into the `model_dir` variable. Then to restore this model we create a new `tf.Session` class and the `tf.train.import_meta_graph()` method to load the graph and parameters into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_dir = '../exp_unet/checkpoint'\n",
    "model_dir = '../pretrained/unet'\n",
    "\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.import_meta_graph(\"%s/model.ckpy.meta\" % model_dir)\n",
    "saver.restore(sess, \"%s/model.ckpy\" % model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the named Graph collections specified during the training process, we can quickly reload handles to the key placeholders of our graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, mode, mask = tf.get_collection(\"inputs\")\n",
    "pred = tf.get_collection(\"outputs\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running inference\n",
    "\n",
    "Now that the graph structure is restored, we simply use the same `sess.run()` method to pass new data into their respective placeholders. As before, we will use the `data.load()` method to load new instances of validation data. Feel free to re-run the following cell repeatedly (ctrl + Enter) to see the network in action:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dat, lbl, msk = data.load(mode='train', n=1, return_mask=True)\n",
    "argmax = sess.run(pred, {X: dat, mode: False})\n",
    "argmax = np.argmax(argmax, axis=3)\n",
    "argmax[msk[..., 0] == 0] = 0\n",
    "\n",
    "imshow(dat[..., 1], lbl=lbl if lbl.any() else None, title='FLAIR (ground-truth)')\n",
    "imshow(dat[..., 1], lbl=argmax if argmax.any() else None, title='FLAIR (prediction)')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
